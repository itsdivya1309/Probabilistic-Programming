{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7cc7f74-fb67-4c88-94d8-09b0edbac90f",
   "metadata": {},
   "source": [
    "## Import a tsf file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a8f2634-d103-4443-b366-be91edb879b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all the libraries\n",
    "import os\n",
    "import aeon\n",
    "from aeon.datasets import load_from_tsf_file, write_to_tsfile\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55635846-08f1-4505-83ee-c9adb7774cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = os.path.join(os.path.dirname(aeon.__file__), \"datasets\\\\data\\\\\")\n",
    "data, metadata = load_from_tsf_file(DATA_PATH+\"m1_yearly_dataset\\\\m1_yearly_dataset.tsf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ebce7f1-86a5-426f-b16e-4389cfe6949a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>series_name</th>\n",
       "      <th>start_timestamp</th>\n",
       "      <th>series_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T1</td>\n",
       "      <td>1972-01-01</td>\n",
       "      <td>[3600.0, 7700.0, 12300.0, 30500.0, 47390.0, 57...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T2</td>\n",
       "      <td>1974-01-01</td>\n",
       "      <td>[12654.0, 22879.0, 34164.0, 49524.0, 64761.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T3</td>\n",
       "      <td>1974-01-01</td>\n",
       "      <td>[2142.0, 12935.0, 19130.0, 30500.0, 48177.0, 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>T4</td>\n",
       "      <td>1974-01-01</td>\n",
       "      <td>[5774.0, 7650.0, 9271.0, 21447.0, 28998.0, 409...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>T5</td>\n",
       "      <td>1976-01-01</td>\n",
       "      <td>[432312.0, 569011.0, 862673.0, 1155640.0, 1439...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  series_name start_timestamp  \\\n",
       "0          T1      1972-01-01   \n",
       "1          T2      1974-01-01   \n",
       "2          T3      1974-01-01   \n",
       "3          T4      1974-01-01   \n",
       "4          T5      1976-01-01   \n",
       "\n",
       "                                        series_value  \n",
       "0  [3600.0, 7700.0, 12300.0, 30500.0, 47390.0, 57...  \n",
       "1  [12654.0, 22879.0, 34164.0, 49524.0, 64761.0, ...  \n",
       "2  [2142.0, 12935.0, 19130.0, 30500.0, 48177.0, 5...  \n",
       "3  [5774.0, 7650.0, 9271.0, 21447.0, 28998.0, 409...  \n",
       "4  [432312.0, 569011.0, 862673.0, 1155640.0, 1439...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.head(5)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cad7215e-a3b4-4cbe-81ac-29d54e6806b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas._libs.tslibs.timestamps.Timestamp"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data.iloc[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "188f8833-0dff-4928-a882-878c2ea951ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices=[]\n",
    "datas=[]\n",
    "for i in range(0,4):\n",
    "    indices.append(pd.date_range(start=data['start_timestamp'][i], periods=len(data['series_value'][i]), freq='YS').tolist())\n",
    "    datas.append(pd.Series(data['series_value'][i], index=indices[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42fabfa6-f87e-4eee-a42d-5d11777a9db8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>T1</th>\n",
       "      <th>T2</th>\n",
       "      <th>T3</th>\n",
       "      <th>T4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1972-01-01</td>\n",
       "      <td>3600.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1973-01-01</td>\n",
       "      <td>7700.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1974-01-01</td>\n",
       "      <td>12300.0</td>\n",
       "      <td>12654.0</td>\n",
       "      <td>2142.0</td>\n",
       "      <td>5774.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1975-01-01</td>\n",
       "      <td>30500.0</td>\n",
       "      <td>22879.0</td>\n",
       "      <td>12935.0</td>\n",
       "      <td>7650.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1976-01-01</td>\n",
       "      <td>47390.0</td>\n",
       "      <td>34164.0</td>\n",
       "      <td>19130.0</td>\n",
       "      <td>9271.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       index       T1       T2       T3      T4\n",
       "0 1972-01-01   3600.0      NaN      NaN     NaN\n",
       "1 1973-01-01   7700.0      NaN      NaN     NaN\n",
       "2 1974-01-01  12300.0  12654.0   2142.0  5774.0\n",
       "3 1975-01-01  30500.0  22879.0  12935.0  7650.0\n",
       "4 1976-01-01  47390.0  34164.0  19130.0  9271.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'T1':datas[0], 'T2':datas[1],'T3':datas[2],'T4':datas[3]})\n",
    "df.reset_index(drop=False, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "19e263fa-0828-4f81-b182-cdc724414fc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1972-01-01'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['index'] = pd.to_datetime(df['index'])\n",
    "df['index'] = df['index'].dt.strftime('%Y-%m-%d')\n",
    "df.iloc[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "324c862c-d9f7-4f25-9c5c-4572f0dc4659",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31, 5)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e8fd3751-ebf6-4025-b760-1c36379de07f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'frequency': 'yearly',\n",
       " 'forecast_horizon': 6,\n",
       " 'contain_missing_values': False,\n",
       " 'contain_equal_length': False}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9579bbc2-d4ea-4053-9665-34cb38091764",
   "metadata": {},
   "source": [
    "## The purpose is to convert the dataframe df into a tsf file.\n",
    "\n",
    "_write_to_tsf_file():\n",
    "\n",
    "    write_dataframe_to_tsf_file():\n",
    "    \n",
    "        _write_header_tsf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "717e49ad-94fb-4b83-9e8b-e79b7d3f8d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import textwrap\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6af5d789-50b8-440d-86d0-fb0d6e1ffe35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_tsf_file(\n",
    "    X, path, y=None, problem_name=\"sample_data.tsf\", header=None, horizon=0\n",
    "):\n",
    "    \"\"\"Write an aeon collection of time series to text file in .tsf format.\n",
    "\n",
    "    Write metadata and data stored in aeon compatible data set to file.\n",
    "    A description of the tsf format is in examples/load_data.ipynb.\n",
    "\n",
    "    Note that this file is structured to still support the\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : pd.DataFrame, each cell a pd.Series\n",
    "        Collection of time series: univariate, multivariate, equal or unequal length.\n",
    "    path : string.\n",
    "        Location of the directory to write file\n",
    "    y: None or pd.Series, default = None\n",
    "        Response variable, discrete for classification, continuous for regression\n",
    "        None if clustering.\n",
    "    problem_name : string, default = \"sample_data\"\n",
    "        The file is written to <path>/<problem_name>/<problem_name>.tsf\n",
    "    header: string, default = None\n",
    "        Optional text at the top of the file that is ignored when loading.\n",
    "    \"\"\"\n",
    "    if not (\n",
    "        isinstance(X, pd.DataFrame)\n",
    "    ):\n",
    "        raise TypeError(\n",
    "            f\" Wrong input data type {type(X)} convert to pd.DataFrame\"\n",
    "        )\n",
    "\n",
    "    # See if passed file name contains .tsf extension or not\n",
    "    split = problem_name.split(\".\")\n",
    "    if split[-1] != \"tsf\":\n",
    "        problem_name = problem_name + \".tsf\"\n",
    "\n",
    "    _write_dataframe_to_tsf_file(\n",
    "        X, \n",
    "        path, \n",
    "        problem_name, \n",
    "        y=y,\n",
    "        horizon=horizon,\n",
    "        comment=header\n",
    "    ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f25fa002-443d-4d82-8d2e-3ff9e355ecca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _write_dataframe_to_tsf_file(\n",
    "    X, path, problem_name=\"sample_data\", y=None, horizon=0, comment=None\n",
    "):\n",
    "    # ensure data provided is a dataframe\n",
    "    if not isinstance(X, pd.DataFrame):\n",
    "        raise ValueError(f\"Data provided must be a DataFrame, passed a {type(X)}\")\n",
    "    # See if passed file name contains .tsf extension or not\n",
    "    split = problem_name.split(\".\")\n",
    "    if split[-1] != \"tsf\":\n",
    "        problem_name = problem_name + \".tsf\"\n",
    "    equal_length = not X.isnull().values.any()\n",
    "    missing = X.isnull().values.any()\n",
    "    columns = X.dtypes.to_dict()\n",
    "    for i in columns.keys():\n",
    "        if columns[i]=='float64' or columns[i]=='int32' or columns[i]=='int64':\n",
    "            columns[i]='numeric'\n",
    "        if columns[i]=='datetime64[ns]':\n",
    "            columns[i]='date'\n",
    "        else:\n",
    "            columns[i]='string'\n",
    "    file = _write_header_tsf(\n",
    "        path,\n",
    "        problem_name,\n",
    "        attribute=columns,\n",
    "        equal_length=equal_length,\n",
    "        frequency=calculate_frequency(X),\n",
    "        horizon=horizon,\n",
    "        missing=missing,\n",
    "        comment=comment,\n",
    "        suffix=None,\n",
    "    )\n",
    "    n_cases, n_channels = X.shape\n",
    "    \n",
    "    for j in range(0, n_channels):\n",
    "        column_name = X.columns[j]\n",
    "        file.write(f\"{column_name}:\")\n",
    "        \n",
    "        for i in range(0, n_cases):\n",
    "            series = X.iloc[i, j]\n",
    "            # Check if the value is NaN\n",
    "            if pd.notna(series):\n",
    "                series_str = str(series)\n",
    "            else:\n",
    "                series_str = '?'  # Replace NaN with a ?\n",
    "                \n",
    "            # Write the series string to the file\n",
    "            file.write(f\"{series_str},\")\n",
    "        # Check if y is not None before accessing its elements\n",
    "        if y is not None:\n",
    "            file.write(f\"{y[i]}\\n\")\n",
    "        else:\n",
    "            file.write(\"\\n\")  # Write a newline if y is None\n",
    "    file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7c41fe7e-ce15-4a5e-999d-e997f3eaa7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_frequency(df):\n",
    "    # Convert timestamps to DateTime format\n",
    "    df['Timestamp'] = pd.to_datetime(df.index)\n",
    "\n",
    "    # Calculate time differences\n",
    "    time_diffs = df['Timestamp'].diff().dropna()\n",
    "\n",
    "    # Calculate median time difference\n",
    "    median_diff = time_diffs.median()\n",
    "\n",
    "    # Determine frequency based on median time difference\n",
    "    if median_diff <= pd.Timedelta(days=1):\n",
    "        frequency = \"daily\"\n",
    "    elif median_diff <= pd.Timedelta(weeks=1):\n",
    "        frequency = \"weekly\"\n",
    "    elif median_diff <= pd.Timedelta(days=30):\n",
    "        frequency = \"monthly\"\n",
    "    elif median_diff <= pd.Timedelta(days=365):\n",
    "        frequency = \"yearly\"\n",
    "    else:\n",
    "        frequency = \"other\"  # You can define more granular frequencies as needed\n",
    "    df.drop('Timestamp', axis=1, inplace=True)\n",
    "\n",
    "    return frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4b5c79a2-a418-42e1-aedd-6389f0a22d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _write_header_tsf(\n",
    "    path,\n",
    "    problem_name,\n",
    "    attribute={'col':'data_type'},\n",
    "    equal_length=True,\n",
    "    frequency=\"weekly\",\n",
    "    horizon=0,\n",
    "    missing=False,\n",
    "    comment=None,\n",
    "    suffix=None,\n",
    "):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    if suffix is not None:\n",
    "        load_path = load_path + suffix   \n",
    "    # See if passed file name contains .tsf extension or not\n",
    "    split = problem_name.split(\".\")\n",
    "    if split[-1] != \"tsf\":\n",
    "        problem_name = problem_name + \".tsf\"       \n",
    "    load_path = f\"{path}/{problem_name}\"\n",
    "    \n",
    "    file = open(load_path, \"w\")\n",
    "\n",
    "    if comment is not None:\n",
    "        file.write(\"\\n# \".join(textwrap.wrap(\"# \" + comment)))\n",
    "        file.write(\"\\n\")\n",
    "        \n",
    "    file.write(f\"@relation {str(split[0]).lower()}\\n\")\n",
    "    # Write attribute metadata for each column\n",
    "    if attribute is not None:\n",
    "        for attr in attribute:\n",
    "            file.write(f\"@attribute {str(attr)} {str(attribute[attr])}\\n\")\n",
    "    file.write(f\"@frequency {str(frequency).lower()}\\n\")\n",
    "    file.write(f\"@horizon {str(horizon).lower()}\\n\")\n",
    "    file.write(f\"@missing {str(missing).lower()}\\n\")\n",
    "    file.write(f\"@equallength {str(equal_length).lower()}\\n\")\n",
    "    file.write(\"@data\\n\")\n",
    "\n",
    "    return file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b1dc414a-5b94-43d5-802d-ff205327107a",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_to_tsf_file(df, \"D:\\Python\\Project\\Aeon\", y=None, problem_name=\"sample_data\", header=None, horizon=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8968098c-ecbd-4152-b394-48e83867746f",
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "Missing attributes/values in series.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m data, metadata \u001b[38;5;241m=\u001b[39m load_from_tsf_file(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mD:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mPython\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mProject\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mAeon\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124msample_data.tsf\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mD:\\Python\\Project\\Aeon\\aeon\\aeon\\datasets\\_data_loaders.py:829\u001b[0m, in \u001b[0;36mload_from_tsf_file\u001b[1;34m(full_file_path_and_name, replace_missing_vals_with, value_column_name, return_type)\u001b[0m\n\u001b[0;32m    826\u001b[0m full_info \u001b[38;5;241m=\u001b[39m line\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    828\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(full_info) \u001b[38;5;241m!=\u001b[39m (\u001b[38;5;28mlen\u001b[39m(col_names) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m--> 829\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing attributes/values in series.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    831\u001b[0m series \u001b[38;5;241m=\u001b[39m full_info[\u001b[38;5;28mlen\u001b[39m(full_info) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    832\u001b[0m series \u001b[38;5;241m=\u001b[39m series\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mException\u001b[0m: Missing attributes/values in series."
     ]
    }
   ],
   "source": [
    "data, metadata = load_from_tsf_file(\"D:\\Python\\Project\\Aeon\\sample_data.tsf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7daebf-ce96-4462-aa91-4747ec6f56b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
